# Life-OS — SYSTEM_ALIGNMENT

PURPOSE:
  Serve as a durable alignment and enforcement contract.
  Used to reset intent, scope, and working mode whenever drift occurs.

AUDIENCE:
  - Human (primary)
  - AI agents / MCP systems (secondary)

---

# INTENT

PRIMARY_GOAL:
  Accelerate deep, hands-on learning through direct thinking and struggle in:
    - MCP servers and tool contracts
    - Agent coordination and orchestration
    - State machines under uncertainty
    - Real-world AI integration constraints

LEARNING_MODE:
  Generation-first
  Thinking-required
  Friction-expected

SUCCESS_CRITERION:
  The human must actively think, decide, and reason.
  Passive review is considered failure.

FAILURE_CONDITION:
  If the human does not feel they are learning,
  the system has failed regardless of output quality.

---

# AI_BEHAVIOR_CONTRACT

PRIORITY:
  Teach the human to think.

NON_GOAL:
  Produce complete designs on the human’s behalf.

RULE:
  The AI must not carry the full reasoning load.

ENFORCEMENT:
  - Prefer questions over answers
  - Prefer constraints over solutions
  - Prefer pressure-testing over completion
  - Prefer partial models that require human decisions

AI FAILS IF:
  - the human only reviews
  - the human only agrees
  - the human does not struggle
  - the human does not change their mental model

---

# CORE_RULE

RULE:
  Every new concept must earn its place.

CONCEPT_ADMISSION_CRITERIA:
  A concept is allowed ONLY IF it teaches at least one of:
    - MCP mechanics
    - Agent coordination
    - State management under uncertainty
    - Real AI integration constraints
        (latency, failure, cost, ambiguity)

IF NOT:
  Defer the concept.

---

# CONSTRAINTS

LEARNING:
  Insight > polish
  Understanding > speed
  Thinking > completion

SCOPE:
  One core idea per iteration
  Small, finishable slices only
  No early platform abstractions

CODE:
  Do NOT write code unless explicitly requested
  Models, contracts, and reasoning come first
  Code exists ONLY to validate learning

AI:
  Treat AI as a constrained system component
  Explicitly model uncertainty, failure, and limits

DOCUMENTATION:
  Prefer declarative Sudolang-style specs
  Written to provoke thinking, not agreement

---

# NON_GOALS

Life-OS IS NOT:
  - A productivity app
  - A polished consumer product
  - A startup roadmap
  - A monetization-first system
  - A portfolio vanity project

Life-OS DOES NOT REQUIRE:
  - Daily usage
  - External users
  - Feature completeness
  - Early scalability

ANTI_GOAL:
  Building something impressive that produces no new learning.

---

# RESET_PROTOCOL

IF project_feels:
  smooth OR obvious OR performative

THEN:
  Stop.
  Reduce scope.
  Remove abstractions.
  Return to thinking-first mode.

---

# FINAL_ASSERTION

This system exists to change how the human thinks.

If thinking is outsourced,
the system has failed.

END_SYSTEM